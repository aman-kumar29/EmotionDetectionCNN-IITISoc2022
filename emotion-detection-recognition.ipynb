{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport cv2\nimport numpy as np\nimport itertools\nimport os\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten,Activation,BatchNormalization\n\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50,VGG16, InceptionResNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.models import load_model\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:26.522377Z","iopub.execute_input":"2022-08-11T10:35:26.523052Z","iopub.status.idle":"2022-08-11T10:35:26.529655Z","shell.execute_reply.started":"2022-08-11T10:35:26.523017Z","shell.execute_reply":"2022-08-11T10:35:26.528414Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def plot_images(img_dir, top=10):\n    all_img_dirs = os.listdir(img_dir)\n    img_files = [os.path.join(img_dir, file) for file in all_img_dirs][:5]\n    plt.figure(figsize=(10, 10))  \n    for idx, img_path in enumerate(img_files):\n        plt.subplot(5, 5, idx+1)\n        img = plt.imread(img_path)\n        plt.tight_layout()        \n        plt.axis('off')\n        plt.imshow(img, cmap='gray') ","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:08.977283Z","iopub.execute_input":"2022-08-11T10:35:08.978245Z","iopub.status.idle":"2022-08-11T10:35:08.986634Z","shell.execute_reply.started":"2022-08-11T10:35:08.978207Z","shell.execute_reply":"2022-08-11T10:35:08.985517Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_dir = \"../input/fer2013/train\" #passing the path with training images\ntest_dir = \"../input/fer2013/test\"  #passing the path with testing images","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:11.659914Z","iopub.execute_input":"2022-08-11T10:35:11.660989Z","iopub.status.idle":"2022-08-11T10:35:11.669401Z","shell.execute_reply.started":"2022-08-11T10:35:11.660947Z","shell.execute_reply":"2022-08-11T10:35:11.666121Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## ANGRY","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/angry')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:29.297284Z","iopub.execute_input":"2022-08-11T10:35:29.297923Z","iopub.status.idle":"2022-08-11T10:35:29.637688Z","shell.execute_reply.started":"2022-08-11T10:35:29.297885Z","shell.execute_reply":"2022-08-11T10:35:29.636762Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## DISGUST","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/disgust')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:33.093159Z","iopub.execute_input":"2022-08-11T10:35:33.093753Z","iopub.status.idle":"2022-08-11T10:35:33.422434Z","shell.execute_reply.started":"2022-08-11T10:35:33.093716Z","shell.execute_reply":"2022-08-11T10:35:33.421541Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## FEAR","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/fear')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:35.608738Z","iopub.execute_input":"2022-08-11T10:35:35.609461Z","iopub.status.idle":"2022-08-11T10:35:35.948955Z","shell.execute_reply.started":"2022-08-11T10:35:35.609424Z","shell.execute_reply":"2022-08-11T10:35:35.947846Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## HAPPY","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/happy')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:38.261286Z","iopub.execute_input":"2022-08-11T10:35:38.262202Z","iopub.status.idle":"2022-08-11T10:35:38.605864Z","shell.execute_reply.started":"2022-08-11T10:35:38.262152Z","shell.execute_reply":"2022-08-11T10:35:38.604767Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## NEUTRAL","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/neutral')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:40.819644Z","iopub.execute_input":"2022-08-11T10:35:40.820030Z","iopub.status.idle":"2022-08-11T10:35:41.168323Z","shell.execute_reply.started":"2022-08-11T10:35:40.819986Z","shell.execute_reply":"2022-08-11T10:35:41.167385Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## SAD","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/sad')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:43.364203Z","iopub.execute_input":"2022-08-11T10:35:43.365190Z","iopub.status.idle":"2022-08-11T10:35:43.702638Z","shell.execute_reply.started":"2022-08-11T10:35:43.365141Z","shell.execute_reply":"2022-08-11T10:35:43.701748Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## SURPRISE","metadata":{}},{"cell_type":"code","source":"plot_images(train_dir+'/surprise')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:46.768146Z","iopub.execute_input":"2022-08-11T10:35:46.768503Z","iopub.status.idle":"2022-08-11T10:35:47.555125Z","shell.execute_reply.started":"2022-08-11T10:35:46.768473Z","shell.execute_reply":"2022-08-11T10:35:47.554002Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":" ### Plotting the number of images in each emotion folders","metadata":{}},{"cell_type":"code","source":"def plot_bar_chart_diagram(path_data):\n  dic={}\n  for emotion in  os.listdir(path_data):\n    dem=0\n    for x in os.listdir(path_data+\"/\"+emotion):\n      dem+=1\n    dic[emotion]=dem\n  print(dic)\n  barlist=plt.bar(range(len(dic)), list(dic.values()),tick_label=list(dic.keys()))\n#set color\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:51.535554Z","iopub.execute_input":"2022-08-11T10:35:51.535936Z","iopub.status.idle":"2022-08-11T10:35:51.542545Z","shell.execute_reply.started":"2022-08-11T10:35:51.535901Z","shell.execute_reply":"2022-08-11T10:35:51.541134Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"plot_bar_chart_diagram(train_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:54.751549Z","iopub.execute_input":"2022-08-11T10:35:54.751990Z","iopub.status.idle":"2022-08-11T10:35:54.952016Z","shell.execute_reply.started":"2022-08-11T10:35:54.751953Z","shell.execute_reply":"2022-08-11T10:35:54.950978Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"plot_bar_chart_diagram(test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:35:57.961247Z","iopub.execute_input":"2022-08-11T10:35:57.961609Z","iopub.status.idle":"2022-08-11T10:35:58.153477Z","shell.execute_reply.started":"2022-08-11T10:35:57.961577Z","shell.execute_reply":"2022-08-11T10:35:58.152401Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"img_size = 48","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:36:01.271467Z","iopub.execute_input":"2022-08-11T10:36:01.271831Z","iopub.status.idle":"2022-08-11T10:36:01.276785Z","shell.execute_reply.started":"2022-08-11T10:36:01.271800Z","shell.execute_reply":"2022-08-11T10:36:01.275562Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_data_gen = ImageDataGenerator(width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1./255\n                                         )\nvalidation_data_gen = ImageDataGenerator(rescale=1./255)\n\n# Preprocess all test images\ntrain_generator = train_data_gen.flow_from_directory(\n        '../input/fer2013/train',\n        target_size=(48, 48),\n        batch_size=64,\n        class_mode='categorical')\n\nvalidation_generator = validation_data_gen.flow_from_directory(\n        '../input/fer2013/test',\n        target_size=(48, 48),\n        batch_size=64,\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:16:50.692750Z","iopub.execute_input":"2022-08-11T09:16:50.693124Z","iopub.status.idle":"2022-08-11T09:17:12.815464Z","shell.execute_reply.started":"2022-08-11T09:16:50.693091Z","shell.execute_reply":"2022-08-11T09:17:12.814419Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model Without Deep Learning","metadata":{}},{"cell_type":"code","source":"# model= tf.keras.models.Sequential()\n# model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,3)))\n# model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n    \n# model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Flatten()) \n# model.add(Dense(256,activation = 'relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.25))\n    \n# model.add(Dense(512,activation = 'relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.25))\n\n# model.add(Dense(7, activation='softmax'))\n\n# model.compile(\n#     optimizer = Adam(lr=0.0001), \n#     loss='categorical_crossentropy', \n#     metrics=['accuracy']\n#   )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Simple early stopping\n# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n# mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator,callbacks=[es, mc])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model WIth Transfer Learning","metadata":{}},{"cell_type":"code","source":"#using pretrained model, RESNET50 architecture\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nbase_model = ResNet50(input_shape=(48,48,3),include_top = False, weights = 'imagenet')\n\nbase_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:17:21.820074Z","iopub.execute_input":"2022-08-11T09:17:21.820430Z","iopub.status.idle":"2022-08-11T09:17:23.168583Z","shell.execute_reply.started":"2022-08-11T09:17:21.820399Z","shell.execute_reply":"2022-08-11T09:17:23.167565Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"emotion_model = Sequential()\nemotion_model.add(base_model)\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Flatten())\nemotion_model.add(BatchNormalization())\nemotion_model.add(Dense(32,kernel_initializer='he_uniform'))\nemotion_model.add(BatchNormalization())\nemotion_model.add(Activation('relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(32,kernel_initializer='he_uniform'))\nemotion_model.add(BatchNormalization())\nemotion_model.add(Activation('relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(32,kernel_initializer='he_uniform'))\nemotion_model.add(BatchNormalization())\nemotion_model.add(Activation('relu'))\nemotion_model.add(Dense(7,activation='softmax'))\n\n\nemotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:17:36.464921Z","iopub.execute_input":"2022-08-11T09:17:36.465782Z","iopub.status.idle":"2022-08-11T09:17:36.483448Z","shell.execute_reply.started":"2022-08-11T09:17:36.465738Z","shell.execute_reply":"2022-08-11T09:17:36.482121Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(emotion_model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:17:40.932428Z","iopub.execute_input":"2022-08-11T09:17:40.933051Z","iopub.status.idle":"2022-08-11T09:17:41.875904Z","shell.execute_reply.started":"2022-08-11T09:17:40.933014Z","shell.execute_reply":"2022-08-11T09:17:41.874824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\nmc = ModelCheckpoint('model_resnet.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:17:49.629748Z","iopub.execute_input":"2022-08-11T09:17:49.630417Z","iopub.status.idle":"2022-08-11T09:17:49.638721Z","shell.execute_reply.started":"2022-08-11T09:17:49.630369Z","shell.execute_reply":"2022-08-11T09:17:49.637747Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = emotion_model.fit_generator(train_generator,steps_per_epoch=28709 // 64,epochs = 60,validation_data = validation_generator,callbacks=[lrd,mc,es],verbose = 1,validation_steps=7178 // 64)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:17:52.037888Z","iopub.execute_input":"2022-08-11T09:17:52.038592Z","iopub.status.idle":"2022-08-11T10:03:44.161528Z","shell.execute_reply.started":"2022-08-11T09:17:52.038549Z","shell.execute_reply":"2022-08-11T10:03:44.160497Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_json = emotion_model.to_json()\nwith open(\"emotion_model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nemotion_model.save_weights(\"emotion_model_weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:19:16.887325Z","iopub.execute_input":"2022-08-11T10:19:16.887695Z","iopub.status.idle":"2022-08-11T10:19:17.267248Z","shell.execute_reply.started":"2022-08-11T10:19:16.887664Z","shell.execute_reply":"2022-08-11T10:19:17.266225Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:19:41.939798Z","iopub.execute_input":"2022-08-11T10:19:41.940187Z","iopub.status.idle":"2022-08-11T10:19:42.277671Z","shell.execute_reply.started":"2022-08-11T10:19:41.940155Z","shell.execute_reply":"2022-08-11T10:19:42.276742Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap='viridis'):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.style.use('seaborn-darkgrid')\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:24:58.919312Z","iopub.execute_input":"2022-08-11T10:24:58.920048Z","iopub.status.idle":"2022-08-11T10:24:58.929208Z","shell.execute_reply.started":"2022-08-11T10:24:58.919992Z","shell.execute_reply":"2022-08-11T10:24:58.927898Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"classes= ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:26:03.482515Z","iopub.execute_input":"2022-08-11T10:26:03.482905Z","iopub.status.idle":"2022-08-11T10:26:03.487868Z","shell.execute_reply.started":"2022-08-11T10:26:03.482871Z","shell.execute_reply":"2022-08-11T10:26:03.486871Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_path=\"../input/emotion-detection-fer/test\"\nvalidation_datagen1= ImageDataGenerator(rescale = 1./255)\ntest1_generator = validation_datagen1.flow_from_directory(directory=test_path, batch_size=64, classes=classes,class_mode=\"categorical\", target_size=(64,64), shuffle=False)\ny_true = test1_generator.classes\ny_hat =  emotion_model.predict(test1_generator)\ny_hat = tf.argmax(y_hat, axis = 1).numpy()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:28:48.700037Z","iopub.execute_input":"2022-08-11T10:28:48.700448Z","iopub.status.idle":"2022-08-11T10:29:10.204207Z","shell.execute_reply.started":"2022-08-11T10:28:48.700413Z","shell.execute_reply":"2022-08-11T10:29:10.203154Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:30:51.486161Z","iopub.execute_input":"2022-08-11T10:30:51.486829Z","iopub.status.idle":"2022-08-11T10:30:51.757675Z","shell.execute_reply.started":"2022-08-11T10:30:51.486793Z","shell.execute_reply":"2022-08-11T10:30:51.756711Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true = y_true, y_pred = y_hat)\nplot_confusion_matrix(cm, classes, cmap = 'Reds')\nplt.savefig('confmat.png')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:34:50.555944Z","iopub.execute_input":"2022-08-11T10:34:50.557424Z","iopub.status.idle":"2022-08-11T10:34:51.075830Z","shell.execute_reply.started":"2022-08-11T10:34:50.557377Z","shell.execute_reply":"2022-08-11T10:34:51.074882Z"},"trusted":true},"execution_count":39,"outputs":[]}]}